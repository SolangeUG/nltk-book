{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning for Sentiment Analysis\n",
    "\n",
    "Today we will learn to build a very simple sentiment predictor, which will allow us to forecast the rating of short product reviews on a scale from very positive (5 stars) to very negative (1 star), based on the content of the text only. \n",
    "We will pretend that we can only see the text, and try to predict how many stars the user gave the product based on its tone. \n",
    "\n",
    "This is a useful exercise for situations in which we don't have a \"star rating\" easily available. For example, if we are running our own business, many users will probably write tweets or Facebook posts in which they state their opinion of the business, and we want to be able to quickly sort the good from the bad reviews.\n",
    "\n",
    "For this project, we start by setting up our Python environment, and downloading a couple of example datasets (Amazon product reviews) from the Internet. These data were collected by [Julian McAuley, UCSD][1]\n",
    "\n",
    "[1]: http://jmcauley.ucsd.edu/data/amazon/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded dataset Baby and saved it to ./data/\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import urllib.request, os, gzip\n",
    "\n",
    "datadir = './data/'\n",
    "\n",
    "def download_data(dataset_name, datadir):\n",
    "    filename = 'reviews_%s_5.json' % dataset_name\n",
    "    filepath = os.path.join(datadir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"Dataset %s has already been downloaded to %s\" % (dataset_name, datadir))\n",
    "    else:\n",
    "        url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/%s.gz' % filename\n",
    "        urllib.request.urlretrieve(url, filepath + \".gz\")\n",
    "        with gzip.open(filepath + \".gz\", 'rb') as fin:\n",
    "            with open(filepath, 'wb') as fout:\n",
    "                fout.write(fin.read())\n",
    "        print(\"Downloaded dataset %s and saved it to %s\" % (dataset_name, datadir))\n",
    "\n",
    "dataset = \"Baby\"\n",
    "download_data(dataset, datadir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we use have been stored in the JSON format, which is a standard format for exchanging data over the Internet. The \"JS\" stands for JavaScript, which we'll learn about in week 5 of the summer of code! But Python allows us to read these data using the json library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 160792 data for dataset Baby\n",
      "\n",
      "{'reviewerID': 'A2H4QWDVXARPAU', 'asin': 'B0000TYHD2', 'reviewerName': 'Erin White \"Erin\"', 'helpful': [7, 8], 'reviewText': \"I bought this pump for my new baby because it just as others below have said it looks more comfortable than others and it is! Including Medela. With my other child I encountered breastfeeding problems and had a horrible cheap pump. Now with my new baby she was born with a heart problem (she is fine now after a long road to recovery) and had to stay in the hospital for an extended length of time. Meanwhile I had other children at home and we live 6 hours away from our family and so I had no choice but to divide my time between the hospital and home, which meant I needed a hospital grade pump originally I rented one from the hospital (Medela) and it made my breasts hurt really bad. On the way home from the hospital I stopped in at Babiesrus and bought this pump because it was on our registry (we studied and found it to be more comfortable and with coupons it was much cheaper than Medela,) and started using it and I have been so happy with it that sometimes I still use it so my husband can give her a bottle! I love that all I have to do is pump it and add a nipple and its ready to go and its also easier to store than regular breastmilk bags from medela and its also less expensive also. I love the quiet operation I can pump while were watching tv and we don't have to turn the tv up!\", 'overall': 5.0, 'summary': 'Has more comforts than Medela!', 'unixReviewTime': 1116547200, 'reviewTime': '05 20, 2005', 'hash': -728712922}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_data(dataset_name, datadir):\n",
    "    filepath = os.path.join(datadir, 'reviews_%s_5.json' % dataset_name)\n",
    "    if not os.path.exists(filepath):\n",
    "        download_data(dataset_name, datadir)\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:                            # read file line by line\n",
    "            item_hash = hash(line)                # we will use this later for partitioning our data \n",
    "            item = json.loads(line)               # convert JSON string to Python dict\n",
    "            item['hash'] = item_hash              # add hash for identification purposes\n",
    "            data.append(item)\n",
    "    print(\"Loaded %d data for dataset %s\" % (len(data), dataset_name))\n",
    "    return data\n",
    "\n",
    "# load the data...\n",
    "baby = load_data(dataset, datadir)\n",
    "\n",
    "# Let's have a look at an example item (item number 9426):\n",
    "print()\n",
    "print(baby[9426])\n",
    "\n",
    "#for i, l in enumerate(baby):\n",
    "#    if l['overall'] == 5.0 and 'horrible' in l['reviewText'] and 'bad' in l['reviewText'] and l['helpful'][0]>0:\n",
    "#        print(i, l['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset contains **160792** data items, with **9 fields** called `reviewTime, asin, reviewerID, reviewText, unixReviewTime, summary, helpful, reviewerName, overall`. For example, this particular review was written on May 20, 2005, by the user 'Erin White \"Erin\"'. Erin summarized the product as \"Has more comforts than Medela!\" and gave it 5 stars (out of 5). 7 out of 8 other users rated this review helpful. We also added a hash, which is a single number summarizing the whole data item. For now we can view it as a random ID that is (extremely likely to be) unique for each data item, a bit like a US social security number.\n",
    "\n",
    "For this project, we will ignore all fields except **reviewText** and **overall** (i.e. the overall rating in stars out of five). **The idea is to find out if we can infer the star rating (how much the user liked the product) by only looking at the text**. This way we can learn how to automatically analyze even texts that come without a star rating, such as Facebook posts or tweets.\n",
    "\n",
    "Before we start building a complicated AI solution, it is good practice to **first implement a very simple \"baseline predictor\" and measure its performance**. This way we get a feeling on how hard (or easy) the problem is. For example, we can check for the presence of certain words with strong positive or negative connotations, such as \"good\" or \"fantastic\" versus \"bad\" or \"poor\". Note that this review contains the words \"horrible\", \"hurt\", \"bad\" and \"problem\", and still received 5 stars. This gives us already a feeling for the difficulty of the sentiment analysis problem.\n",
    "\n",
    "Before we develop our first sentiment predictor, we need to partition our data into a **training set**, a **validation set**, and a **test set**. This is something we should do in all our machine learning projects. The idea is that our predictor might overgeneralize from the examples we show it if we are not careful. This is a bit like a child whom you have shown how an iPad works, and then they try to swipe everything that looks like a screen (the TV, the microwave etc.)\n",
    "\n",
    "For instance, the example review listed above might be the only review with the phrase \"6 hours\" in it, and our predictor might learn a rule that the phrase \"6 hours\" is indicative of a high star rating. Such a rule would be unlikely to generalize well to new reviews that we didn't show to the predictor while it was training. So after training our predictor (using only examples from the training set), we need to be able to measure its performance on reviews it hasn't seen yet, which is what the test set is for. We use the validation set because we may want to explore different predictor variants and get an idea on how well they perform on unseen examples before committing to one.\n",
    "\n",
    "Therefore the **general procedure when developing a predictor using machine learning** is as follows:\n",
    "\n",
    "- Train **several variants** of a predictor using examples from the *training set* only.\n",
    "\n",
    "- Use the predictor performance on the *validation set* to select a single best predictor among all the possible variants. This step also involves debugging our implementation of the predictor, tweaking its parameters, etc.\n",
    "\n",
    "- Use the *test set* to get an idea on how well our best predictor is expected to perform on unseen data. This step should only be performed once, at the very end of the experiment: if we tweak our predictor based on its performance on the test set, we simply may find a variant that \"gets lucky\" on the test set, and overestimate its accuracy on truly unseen examples.\n",
    "\n",
    "- A common rule of thumb is to use 60% of our data for the training, 20% for validation, and 20% for testing. We could simply take the first 60% of our review data for training, but then we have to assume that the dataset has been \"mixed\" well in advance. We achieve a better **randomization** by using the hash we computed from the JSON string and checking its modulus 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 96638 training examples, 32252 validation examples, and 31902 test examples.\n"
     ]
    }
   ],
   "source": [
    "def partition_train_validation_test(data):\n",
    "    # 60% : modulus is 0, 1, 2, 3, 4, or 5\n",
    "    data_train = [item for item in data if item['hash'] % 10 <= 5]\n",
    "    # 20% : modulus is 6 or 7\n",
    "    data_valid = [item for item in data if item['hash'] % 10 in [6,7]] \n",
    "    # 20% : modulus is 8 or 9\n",
    "    data_test  = [item for item in data if item['hash'] % 10 in [8,9]] \n",
    "    return data_train, data_valid, data_test\n",
    "    \n",
    "baby_train, baby_valid, baby_test = partition_train_validation_test(baby)\n",
    "\n",
    "print(\"We have\", len(baby_train), \"training examples,\", len(baby_valid),\n",
    "      \"validation examples, and\", len(baby_test), \"test examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Prediction algorithms generally work with numbers instead of text**. Therefore we need to preprocess our text by extracting from it **numeric \"features\"** that we can afterwards feed into our predictor. \n",
    "\n",
    "For our simple baseline predictor, we will use only two features: the frequency of positive words in the review (\"good\", \"great\", \"like\") and the frequency of negative words in the review (\"bad\", \"horrible\", \"dislike\"). Let's call these two features **fpos** and **fneg**. \n",
    "\n",
    "Our hypothesis is that reviews with many positive words (high fpos) are likely to receive 4 or 5 stars, while reviews with many negative words (high fneg) will probably receive 1 or 2 stars. Since reviews differ in their length, it makes sense to express the frequency of positive and negative words as a fraction of the total number of words in the review. Therefore **fpos** and **fneg** will be numbers between 0 and 1.\n",
    "\n",
    "For example, assume the review text is *\"This is a good, great, fantastic, amazing, wonderful, super product!\"*. We count six positive words and zero negative words (out of ten words in total), so fpos == 0.6 (6/10) and fneg == 0.0 (0/10). \n",
    "On the other hand, the review \"This is a bad, atrocious, terrible, dreadful, awful, abysmal product!\" will have fpos == 0.0 (0/10) and fneg == 0.6 (6/10). \n",
    "\n",
    "Alternatively we could decide to discount all **stop words**: these are extremely common words such as \"this\", \"is\" or \"a\", which are required by the syntax of the English language but don't really carry semantic meaning. If we strip out these three words, we have fpos == 0.857 (6/7) in the first example, and fneg == 0.857 in the second example.\n",
    "\n",
    "Writing down all positive and negative words in the English language by hand would be a very long and tedious task. Thankfully we don't have to do this ourselves, since it was already done by Hu and Liu. The [Hu-Liu lexicon of positive and negative opinion words][1] is available as part of NLTK.\n",
    "\n",
    "\n",
    "[1]: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some positive words: affluent, impressiveness, unmatched, quicker, intriguing, enthralled, loved, astonish, useable, covenant\n",
      "Some negative words: shipwreck, haphazard, sloooooooooooooow, vengeance, discouragingly, ultimatums, fleeing, menial, partisans, procrastinate\n",
      "Words that appear in both sets: envious, enviously, enviousness\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "import random\n",
    "\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "random.seed(1234)\n",
    "print(\"Some positive words:\", \", \".join(random.sample(positive_words, 10)))\n",
    "print(\"Some negative words:\", \", \".join(random.sample(negative_words, 10)))\n",
    "\n",
    "intersection = positive_words & negative_words\n",
    "print(\"Words that appear in both sets: \" + \", \".join(intersection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While **sentiment labeling** of individual words can be subjective, most people would agree with the classification as positive or negative for these examples. Notice that the Hu-Liu lexicon contains different word forms: for example, it contains both adjectives (\"wholesome\") and adverbs (\"harshly\"), and verbs appear both in the base form (\"blurt\") and in inflected forms (\"picketing\"). It also contains common misspellings (\"flicering\" instead of \"flickering\"). \n",
    "\n",
    "This is why **we will take the words in the reviews as they are** (apart from minor preprocessing steps such as converting from upper-case to lower-case), and won't apply more sophisticated preprocessing techniques such as stemming.\n",
    "\n",
    "We can now **write a function that takes a review text and outputs the number of positive and negative words in the review as a fraction of the total number of words in the review (excluding stop words and punctuation)**. \n",
    "\n",
    "Note that we have to deal with the special case when the total number of words is zero, which happens if the review text is empty. Otherwise we'll end up dividing by zero, and you'll remember from high school that this is not allowed!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8571428571428571, 0.0)\n",
      "(0.0, 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# English language stop words\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def my_tokenize(text):\n",
    "    \"\"\"\n",
    "    Split text into lower-case tokens, removing all-punctuation tokens and stopwords\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        tokens.extend(x for x in word_tokenize(sentence.lower()) \n",
    "                      if x not in eng_stopwords and any(i.isalpha() for i in x))\n",
    "    return tokens\n",
    "\n",
    "def pos_neg_fraction(text):\n",
    "    \"\"\"\n",
    "    Return the fraction of positive and negative words in a text\n",
    "    \"\"\"\n",
    "    tokens = my_tokenize(text)\n",
    "    count_pos, count_neg = 0, 0\n",
    "    for t in tokens:\n",
    "        if t in positive_words:\n",
    "            count_pos += 1\n",
    "        if t in negative_words:\n",
    "            count_neg += 1\n",
    "    count_all = len(tokens)\n",
    "    if count_all != 0:\n",
    "        return count_pos/count_all, count_neg/count_all\n",
    "    else:\n",
    "        return 0., 0.\n",
    "    \n",
    "pos_example = 'This is a good, great, fantastic, amazing, wonderful, super product!!!'\n",
    "neg_example = 'This is a bad, atrocious, terrible, dreadful, awful, abysmal product!!!'\n",
    "\n",
    "print(pos_neg_fraction(pos_example))\n",
    "print(pos_neg_fraction(neg_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For our two example sentences, this seems to do what we want. Obviously, real reviews usually don't have such an extreme concentration of positive or negative words. Let's find the reviews in our real-world datasets with the highest fraction of positive and negative words, respectively. \n",
    "\n",
    "When exploring the data, it is generally a good idea to **restrict ourselves to the training data only**, to avoid \"peeking ahead\" and designing our algorithm so that it works well for the test examples we see.\n",
    "\n",
    "For the subsequent analysis, we convert our training data set into a matrix `X_train` with two columns and as many rows as there are examples in the data set. The **first column** contains the **fraction of positive words**, while the **second column** contains the **fraction of negative words** for each example. \n",
    "\n",
    "We'll use `numpy.array`, which is the standard way to represent matrices in Python. It provides useful helper functions, such as for finding the maximum in each column. Note that the following cell may take a few minutes to run!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a fraction of 100.000000 % positive words for example 5915\n",
      "{'reviewerID': 'AKU0ZZ3IEZW42', 'asin': 'B0001BUKA8', 'helpful': [0, 0], 'reviewText': 'useful peace', 'overall': 5.0, 'summary': 'Five Stars', 'unixReviewTime': 1405382400, 'reviewTime': '07 15, 2014', 'hash': -1114530380}\n",
      "\n",
      "We found a fraction of 100.000000 % negative words for example 15794\n",
      "{'reviewerID': 'A2416HDN71TOGG', 'asin': 'B000HZEQSU', 'reviewerName': 'Elizabeth Evans', 'helpful': [0, 0], 'reviewText': 'uncomfortable', 'overall': 1.0, 'summary': 'One Star', 'unixReviewTime': 1404691200, 'reviewTime': '07 7, 2014', 'hash': 1727535344}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def dataset_to_matrix(data):\n",
    "    \"\"\"Extract our feature matrix from the dataset\"\"\"\n",
    "    return numpy.array([list(pos_neg_fraction(item['reviewText'])) for item in data])\n",
    "\n",
    "X_train = dataset_to_matrix(baby_train)\n",
    "most_pos, most_neg = numpy.argmax(X_train, axis=0)\n",
    "\n",
    "# print the example with the highest fraction of positive words:\n",
    "print(\"We found a fraction of %f %% positive words for example %d\" % \n",
    "      (100. * X_train[most_pos, 0], most_pos))\n",
    "print(baby_train[most_pos])\n",
    "\n",
    "print()\n",
    "\n",
    "# print the example with the highest fraction of negative words:\n",
    "print(\"We found a fraction of %f %% negative words for example %d\" %\n",
    "      (100. * X_train[most_neg, 1], most_neg))\n",
    "print(baby_train[most_neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there actually is an example with 100% positive words (excluding stopwords), which received 5 stars, and also an example with 100% negative words, which received 1 star. Our idea of counting positive and negative words seems promising! We are now almost ready to train our first predictor. The only thing left to do is to collect the numbers we want to predict (the star ratings which are called `overall` in the JSON data), and put them into another NumPy array. We'll call this one **Y_train**.\n",
    "\n",
    "In machine learning parlance, the matrix **X_train** is called the **feature matrix** (what we already know) and the matrix **Y_train** is called the **target vector** (what we want to predict based on the features). You may remember from high-school algebra that vectors are one-dimensional while matrices are two-dimensional. This is because for every example we may have multiple features, but usually a single target. In this case we have two features (fractions of positive and negative examples), so our feature matrix has two columns.\n",
    "\n",
    "Generally, most machine learning algorithms prefer dealing with numbers (matrices) - so we have to find a way to extract numerical information from non-numerical data such as text. This is exactly what we did when counting the fraction of positive and negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our feature matrix is two-dimensional and has shape (96638, 2)\n",
      "\n",
      "Our target vector is one-dimensional and has shape (96638,)\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_targets(data):\n",
    "    \"\"\"Extract our target array from the dataset\"\"\"\n",
    "    return numpy.array([item['overall'] for item in data])\n",
    "\n",
    "Y_train = dataset_to_targets(baby_train)\n",
    "print(\"Our feature matrix is two-dimensional and has shape\", X_train.shape)\n",
    "print()\n",
    "print(\"Our target vector is one-dimensional and has shape\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In a real machine learning project, **now would be a good time to spend more time exploring and visualizing the data**. For example, it is a good idea to get a feeling on **how the features and targets are distributed**, as this determines which techniques are a good fit for the problem. The Python community has created a lot of great tools and libraries for exploratory data analysis - unfortunately we don't have the time to discuss them in detail right now.\n",
    "\n",
    "However, at least we can give you some pointers if you want to study this topic for yourself. We recommend that anyone interested in becoming a data scientist should **have a look at the Pandas library**. \n",
    "\n",
    "For example, if you want to visualize how many 1-star, 2-star etc. ratings there are in the dataset, you can do it like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9872f30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# visualize how many 1-star, 2-star etc. ratings there are in the dataset\n",
    "pandas.Series(Y_train).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see that 5-star review are by far the most frequent, and very few people leave a 1-star review. \n",
    "\n",
    "We can also **visualize the distribution of our features**. We see that most reviews don't have negative words at all (sharp peak around 0), while reviews without any positive words are much rarer. The typical review seems to contain around 10% positive words, and around 5% negative words:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f6b0510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pandas.DataFrame(data=X_train, columns = ['fpos', 'fneg'])\n",
    "\n",
    "# visualize the distribution of our features\n",
    "df.plot.kde(xlim=(-0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two examples are just meant to whet your appetite. To find out more, have a look at the [Pandas documentation][1].\n",
    "\n",
    "\n",
    "### Predictor\n",
    "\n",
    "**We are now ready to train our first predictor**! Generally it's a good idea to keep it simple at the beginning, so we'll start with a method you will probably remember from high school: **linear regression** (also known as **least-squares regression**). \n",
    "\n",
    "If you haven't studied the mathematics before or would like to refresh your memory, there are many good materials on the Internet, e.g. on [Khanacademy][2]. Otherwise you can also use the Python libraries as a \"black box\" - this will be sufficient if you don't plan on working with data a lot.\n",
    "\n",
    "Later this week we'll learn how to use **Google's Tensorflow** library to train a linear regression model: however, that will be mostly for pedagogical purposes, and would be a bit of an overkill in practice. \n",
    "\n",
    "The [**Scikit-learn** library][3] has very good implementations of classical predictors such as linear regression.\n",
    "\n",
    "[1]: https://pandas.pydata.org/pandas-docs/stable/tutorials.html\n",
    "[2]: https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data\n",
    "[3]: http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for the fpos variable is 3.2125333067621376\n",
      "The coefficient for the fneg variable is -5.588852029244575\n",
      "The intercept is 4.010144435455502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "print(\"The coefficient for the fpos variable is\", lreg.coef_[0])\n",
    "print(\"The coefficient for the fneg variable is\", lreg.coef_[1])\n",
    "print(\"The intercept is\", lreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like this, we have trained our first machine learning model! Since linear regression is a very simple predictor, we can actually understand its inner workings quite well. The **intercept** is the star rating we would expect for a review that contains neither positive nor negative words (fpos==0 and fneg==0): according to the model, such a review should get about 4 stars on average.\n",
    "\n",
    "If the review contains 20% positive words (fpos==0.2) but still no negative words (fneg==0), we would expect the following rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 4.652651 stars\n",
      "This is the same as 4.652651 stars\n"
     ]
    }
   ],
   "source": [
    "# review containing 20% positive words and no negative words\n",
    "features = [[0.2, 0]]\n",
    "# then, the expected (predicted) rating would be:\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0.2 * lreg.coef_[0] + 0 * lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the review contains no positive words (fpos==0) but 20% negative words (fneg==0.2), we expect the following rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating is 2.892374 stars\n",
      "This is the same as 2.892374 stars\n"
     ]
    }
   ],
   "source": [
    "# review containing 20% negative words and no positive words\n",
    "features = [[0, 0.2]]\n",
    "# then, the expected (preficted) rating would be:\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating is %f stars\" % expected_rating_A)\n",
    "\n",
    "# we can also compute this explicitly:\n",
    "expected_rating_B = lreg.intercept_ + 0 * lreg.coef_[0] + 0.2 * lreg.coef_[1]\n",
    "print(\"This is the same as %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that **the more positive words we have in our review, the higher the expected star rating** (the coefficient for the first variable is positive). \n",
    "\n",
    "**The more negative words there are in the review, however, the lower is the expected star rating** (the coefficient for the second variable is negative). This is what we would intuitively expect.\n",
    "\n",
    "Remember our two examples from earlier, which contained 100% positive words (\"so cute\") or 100% negative words (\"uncomfortable\"). For these two extreme examples, we get a **very odd prediction**:\n",
    "    \n",
    "    - Calculate the prediction for a 100% positive, and a 100% negative review.\n",
    "    - Repeat this same process for \"Apps for Android\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected rating for a 100 percent positive words review is 7.222678 stars\n",
      "The expected rating for a 100 percent negative words review is -1.578708 stars\n"
     ]
    }
   ],
   "source": [
    "# review containing 100% positive words and no negative words\n",
    "features = [[1.0, 0]]\n",
    "# then, the expected (preficted) rating would be:\n",
    "expected_rating_A = lreg.predict(features)[0]\n",
    "print(\"The expected rating for a 100 percent positive words review is %f stars\" % expected_rating_A)\n",
    "\n",
    "# review containing 100% positive words and no negative words\n",
    "features = [[0, 1.0]]\n",
    "# then, the expected (preficted) rating would be:\n",
    "expected_rating_B = lreg.predict(features)[0]\n",
    "print(\"The expected rating for a 100 percent negative words review is %f stars\" % expected_rating_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since we haven't told our predictor that all ratings must lie between 1 and 5 stars, it became a bit **overenthusiastic** in its predictions for these extreme examples. We can simply **cut off** these unrealistic results: if the predicted star rating is above 5 stars, we set it to 5 stars, and if it is below 1 star, we set it to 1 star. Now we have a practical prediction algorithm, which we can apply to our training dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lreg(features):\n",
    "    expected_rating = lreg.predict(features)\n",
    "    expected_rating[expected_rating > 5.0] = 5.0\n",
    "    expected_rating[expected_rating < 1.0] = 1.0\n",
    "    return expected_rating\n",
    "\n",
    "pred_train = predict_lreg(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random examples first to get a feeling how well this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training example number 0\n",
      "True rating = 5.000000 stars, expected rating = 4.367093 stars\n",
      "Features = 0.111111 / 0.000000\n",
      "Review text = Perfect for new parents. We were able to keep track of baby's feeding, sleep and diaper change schedule for the first two and a half months of her life. Made life easier when the doctor would ask questions about habits because we had it all right there!\n",
      "\n",
      "Training example number 10000\n",
      "True rating = 5.000000 stars, expected rating = 4.371310 stars\n",
      "Features = 0.172414 / 0.034483\n",
      "Review text = I really love all products from JJ Cole and this particular one is just as great as all of their other products.  The only thing to note is that the color was not pure white as it looks in the photo.  It was a slight grayish/purplish hue, which in my case was actually perfect since I was a little hesitant on having a bright white blanket in the stroller.\n",
      "\n",
      "Training example number 20000\n",
      "True rating = 5.000000 stars, expected rating = 4.060101 stars\n",
      "Features = 0.074324 / 0.033784\n",
      "Review text = For the reviewers who think this is difficult to assemble and pack back in the bag...you've obviously never owned a Graco! lol I bought this on clearance (it was a re-packaged item) at another store and it was missing the manual so I had to figure out how to assemble it on my own. It took me about 5 minutes to get it all together and the same amount of time to take it apart. Unfortunately whoever had returned it was a smoker and they tried to cover the stench with fabreze...not pretty, so I had to return it to the store but I'll definitely be buying another one (brand new this time). I'm also amazed at people who complain about not being able to get it though a doorway...seriously?? I'm pretty sure NO playards can fit through a standard doorway. If that's what you need/want then go with a small bassinet with wheels rather than a playard/bassinet combo.Things I love about it:-The mattress pad is machine washable!!! We had to throw out our Graco pack n play because my son threw up all over the mat. We hosed it down, tried to clean it, and it molded...yuck.-The play gym. Play gyms cost between $30-70 so the fact it's thrown in with this playpen is pretty cool. I love that I can use it on the floor or in the playpen.-The changing table. It can be flipped down to the side when not in use and even zipped off.-It's much more study than all the other playards out there and is obviously better in quality as well.Downside:-it's too heavy for me to lift as a pregnant lady but easy for me to wheel around. Fortunately, when the time comes for me to lift it in and out of the car for trips, I'll no longer be pregnant...so this isn't really even a downside.\n",
      "\n",
      "Training example number 30000\n",
      "True rating = 1.000000 stars, expected rating = 3.212234 stars\n",
      "Features = 0.026316 / 0.157895\n",
      "Review text = This is the WORST babyproofing product we have tried. I wish I would have read the reviews before buying but I got these at a big box store. Once the lock was on I couldn't get it off. My fingers were sore from trying to get it to unlock. Finally, I had to unscrew the cabinet knob (which was a feat in itself!) to get it off. These are awful. Listen to the other negative reviews and save yourself some frustration and hassle and buy something else.\n",
      "\n",
      "Training example number 50000\n",
      "True rating = 5.000000 stars, expected rating = 4.411711 stars\n",
      "Features = 0.125000 / 0.000000\n",
      "Review text = This is by far the one of the best items I received at my baby shower. I have used this since day one and still use it now that my baby is three months old. It's a perfect little nest for baby to rest in, and it is also great to snap shots of your little one. I would recommend this to all parents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_training_example(i):\n",
    "    print(\"Training example number\", i)\n",
    "    print(\"True rating = %f stars, expected rating = %f stars\" % (Y_train[i], pred_train[i]))\n",
    "    print(\"Features = %f / %f\" % (X_train[i,0], X_train[i,1]))\n",
    "    print(\"Review text = %s\" % baby_train[i]['reviewText'])\n",
    "    print()\n",
    "\n",
    "for i in [0, 10000, 20000, 30000, 50000]:\n",
    "    analyze_training_example(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Not terrible, but far **from perfect either**. These few examples already show some of the limitations of our approach. For example, example 50000 is a 1-star review which contains only a single negative word (\"hangs\"), so the predictor overestimates the rating.\n",
    "\n",
    "Example 20000 likewise overestimates the rating because it counts words like \"top\" and \"fabulous\", which don't refer to the product itself in this example.\n",
    "\n",
    "Example 30000 is not too far off, but it underestimates the rating because it counts \"regret\" as a negative word and overlooks the preceding \"not\". Sophisticated sentiment analyzers need to account for negation: for example, \"not bad\" should be treated differently from \"bad\". Intensifiers should also be accounted for: in example 10000, \"very disappointed\" is stronger than \"disappointed\", but our predictor doesn't know this.\n",
    "\n",
    "While looking at individual examples is important and instructive, we need a systematic way to measure the prediction quality across all examples. **Scikit-learn provides different evaluation metrics**. The conceptually easiest choice is the **mean absolute error**, which counts by how many stars our predictions are off on average (in either direction).\n",
    "\n",
    "For example, assume we have three examples with true star ratings of 1, 4, 5, and predicted star ratings of 5, 4, 3. Then the first example is off by 4 stars, the second example by 0 stars (predicted and true rating match exactly), and the third example is off by 2 stars. The mean absolute error is therefore (4 + 0 + 2) / 3 = 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training data is 0.830273 stars\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae_train = mean_absolute_error(pred_train, Y_train)\n",
    "print(\"The mean absolute error on the training data is %f stars\" % mae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So it turns out that **we actually aren't that far off, although the accuracy on the validation set is a bit worse than on the training set (which should be expected)**. \n",
    "\n",
    "Once we move to more complex algorithms, however, we'll have to be very careful not to draw premature conclusions from the training set performance: **an algorithm may easily achieve perfect accuracy on the training set, and still completely fail on unseen examples**! (Like a student with a photographic memory who can reproduce all the answers to all the math problems she has seen before, but hasn't understood the underlying general theory: so she cannot compute any answer if we change the numbers in the problem slightly).\n",
    "\n",
    "**We don't look at the accuracy on the test set yet, because this is the very last step we should do once we are convinced we have found the best predictor we can think of and want to run one final test**. For now, we have established that linear regression with the fraction of positive and negative words as features seems to be a reasonable baseline. Can we do better? Stay tuned!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. Calculate the prediction for 100% positive, and 100% negative review (before the cutoff) for \"Apps for Android\" dataset.\n",
    "2. Build a better sentiment analyzer and comment both your code and your data exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
